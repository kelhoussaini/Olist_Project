{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find product **categories** that repeatdely underperform vs others, and understand why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - `product.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have given you the solution to `product.py` in your challenge folder\n",
    "üëâ Copy-paste it to your local olist/product.py folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It provides aggregates at a `product_id` level of the various orders that have taken place with Olist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_training_data` method in `olist/product.py` returns the following DataFrame:\n",
    "\n",
    "  - `product_id` (_str_) _the id of the product_ **UNIQUE**\n",
    "  - `category` (_str_) _the category name (in English)_\n",
    "  - `product_name_length` (_float_) _character length of product name_\n",
    "  - `product_description_length` (_float_) _character length of product description_\n",
    "  - `product_photos_qty` (_int_) _the number of photos for the product_\n",
    "  - `product_weight_g` (_float_) _weight of the product (in g)_\n",
    "  - `product_length_cm` (_float_) _length of the product (in cm)_\n",
    "  - `product_height_cm` (_float_) _height of the product (in cm)_\n",
    "  - `product_width_cm` (_float_) _width of the product (in cm)_\n",
    "  - `price` (_float_) _average price at which the product is sold_\n",
    "  - `wait_time` (_float_) _the average wait time in days for orders in which the product was sold._\n",
    "  - `share_of_five_stars` (_float_) _the share of five star orders for orders in which the product was sold_\n",
    "  - `share_of_one_stars` (_float_) _the share of one star orders for orders in which the product was sold_\n",
    "  - `review_score` (_float_) _the average review score of the order in which each product is sold_\n",
    "  - `n_orders` (_int_) _the number of orders in which the product appeared_\n",
    "  - `quantity` (_int_) _the total number of products sold_\n",
    "  - `sales` (_float_) _the total value of sales in $BRL for the product_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Analysis per product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Inspect the new `Product().get_training_data()` dataframe, for instance by plotting histograms of each variable using `plt.hist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olist.product import Product\n",
    "products = Product().get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Model review_score by an OLS with the continuous feature of your choice, and discover the R-squared and important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Aggregation per product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Build aggregated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function `get_product_cat` which accepts an aggregating method as an argument and returns a DataFrame with each `product_category`'s `quantity` summed and all other non `str` type properties aggregated with the passed method.  \n",
    "For instance `get_product_cat('median')` returns:\n",
    "\n",
    "  - `quantity` (sum)\n",
    "  - `wait_time` (median)\n",
    "  - `review_score` (median)\n",
    "  - `price` (median)\n",
    "  - ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "product_cat = get_product_cat('mean')\n",
    "result = ChallengeResult('products',\n",
    "shape=product_cat.shape,\n",
    "avg_review_score=int(product_cat['review_score'].mean()),\n",
    "avg_price=int(product_cat['price'].mean()),\n",
    "avg_quantity=int(product_cat['quantity'].mean())\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What are the best performing product categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's try to understand _why_ some categories are performing better than others. \n",
    "\n",
    "Using plotly, create different scatterplots, varying `x`, `y`, `color` and `size`, to finds clues about factors impacting the \"review_score\". \n",
    "\n",
    "- Do you notice underperforming product categories?\n",
    "- Can you think of a strategy to improve Olist's profit margin as per the CEO request?\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "Try plotting `product_length_cm` against `wait_time`, with color as `review_score`, and bubble size as \"sales\" for instance\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Causal inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è It seems that large products like furniture, which happen to take longer to deliver, are performing worse than other products. Are consumers disappointed about the product itself, or by the slow delivery time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì To answer that, run an OLS to model `review_score` so as to isolate the true contribution of each product category on customer satisfaction, by holding `wait_time` constant? \n",
    "\n",
    "- Which dataset should you use for this regression? `product_cat` or the entire `products` training dataset?\n",
    "\n",
    "- Which regressors / independent variables / features should you use? \n",
    "\n",
    "Investigate the results: which product categories correlate with higher review_score holding wait_time constant?\n",
    "\n",
    "Feel free to use `return_significative_coef(model)` coded for you in `olist/utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Furniture is no longer in the list of signigicant coefficients. The problem may have come from delivery rather than the product itself! On the contrary, books are regularly driving higher reviews, even after accounting for generally quicker delivery time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations with this final challenge! Don't forget to commit and push your analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
